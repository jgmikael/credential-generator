# credential-generator

The Credential Generator -project aims at developing a capability to turn the application profiles created with the Data Vocabularies -tool (https://github.com/VRK-YTI) into different flavors of W3C conformant Verifiable Credential definitions.  

# Business case for the solution

Interoperability on all levels is a key factor for making digital identites and wallets useful for both natural and legal persons in their life events or business activities. Presently a very dominant part of the work regarding interoperability of digital wallets is, however, focused on the technical interoperability between the different components of the digital wallet infrastructure that would guarantee an ability to exchange proofs of all kinds between different commercial implementations of the architectural framework that the upcoming EU regulation in this area will enforce. In the recently published Architecture Reference Framework 1.0 (ARF) for the development of an interoperable EUDI Wallet solution it is simply stated that: "(Q)EAA Schema Providers publish schemas and vocabularies describing (Q)EAA structure and semantics. - - Common schemas, including by sector-specific organisations are critical for wide-spread adoption of (Q)EAAs."  

https://digital-strategy.ec.europa.eu/en/library/european-digital-identity-wallet-architecture-and-reference-framework   

When an issuer of a proof of any kind - like the abovementioned "(Q)EAA"s or "qualitative electronic attribute attestations" - decides to create an underlying schema for or apply a previously defined schema for the definition of the proof in question, it would be tremendeously important for the semantic interoperability of this proof (and it's underlying schema) that it would be created based on some internationally acknowledged domain specific semantic standard. Even if there is a standard or a reference data model (RDM) of some kind present, the use of these standards require in general lot's of manual work by the implementer, since the standards for the semantics are usually published either as a simple PDF-document, an Excel-sheet, a UML diagram or something similar. In a handful of situations the proposed standard or RDM to be followed is published in a W3C Linked Data enabled format (RDF/OWL, JSON-LD or similar), which makes it possible to provide the issuers of the proofs with the capability of creating credential definitions that are compatible with the W3C VC specification (https://www.w3.org/TR/vc-data-model/)

ยง B.2 
"The primary purpose of the @context property, from a [JSON-LD] perspective, is to convey the meaning of the data and term definitions of the data in a verifiable credential, in a machine readable way. When encoding a pure [JSON] representation, the @context property remains mandatory and provides some basic support for global semantics. The @context property is used to map the globally unique URIs for properties in verifiable credentials and verifiable presentations into short-form alias names, making both the [JSON] and [JSON-LD] representations more human-friendly to read. From a [JSON-LD] perspective, this mapping also allows the data in a credential to be modeled in a network of machine-readable data, by enhancing how the data in the verifiable credential or verifiable presentation relates to a larger machine-readable data graph. This is useful for telling machines how to relate the meaning of data to other data in an ecosystem where parties are unable to coordinate."    

# Description of the process for creating semantically interoperable credential definitions

The first part of the process is already enabled by the Interoperability Platform (or Workbench), developed by the Finnish Ministry of Finance in cooperation with DVV (The Finnish Digitalization Agency). It encompasses the creation of domain specific terminologies (SKOS ontologies) by defining concepts and relationships between concepts that are relevant in a certain domain and linking these conceptual definitions to derived classes and attributes in specific data component libraries (RDF/OWL ontologies), which in turn can be specialized into information exchange instance specific application profiles (SHACL Shapes) (see. https://tietomallit.suomi.fi/model/iow/) 

Once a specific dataset or data product is described as an application profile, specialized from one or several underlying data component libraries, which in turn are linked to standards or reference data models that enable URI-based linking according to W3C Linked Data principles, it can be exported from the toolset in various usable formats like RDF, XML, JSON-LD, JSON, Turtle, OpenAPI etc. 

The aim of this project is to develop a solution and implement a PoC for the last part of the process, which should give the issuer of proofs the capability of creating a W3C VC specification conformant credential definition automatically once the underlying application profile has been either chosen by the issuer (from a repository of application profiles) or created by the issuer (and saved in the same repository).  
